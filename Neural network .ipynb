{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob \n",
    "from scipy.io.wavfile import read\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Flatten, Lambda,Input, concatenate, Conv2DTranspose, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers \n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import keras.backend as K \n",
    "# K.set_image_dim_ordering('tf')\n",
    "print('Image ordering is tf check: ',K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (140767, 128, 51, 1)\n",
      "Shape of Y:  (140767, 1)\n",
      "Number of samples in class: 0 =  9436\n",
      "Number of samples in class: 1 =  9488\n",
      "Number of samples in class: 2 =  9412\n",
      "Number of samples in class: 3 =  9500\n",
      "Number of samples in class: 4 =  9428\n",
      "Number of samples in class: 5 =  9468\n",
      "Number of samples in class: 6 =  9468\n",
      "Number of samples in class: 7 =  9520\n",
      "Number of samples in class: 8 =  9500\n",
      "Number of samples in class: 9 =  9508\n",
      "Number of samples in class: 10 =  41039\n",
      "Number of samples in class: 11 =  5000\n"
     ]
    }
   ],
   "source": [
    "X = np.load('X_FINAL.npy')\n",
    "Y = np.load('Y_FINAL.npy')\n",
    "    \n",
    "print('Shape of X: ',X.shape)\n",
    "print('Shape of Y: ',Y.shape)\n",
    "\n",
    "for lab in range(0,12):\n",
    "    print('Number of samples in class: '+str(lab) +' = ',len(np.where(Y==lab)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training:  (130000, 128, 51, 1)\n",
      "Shape of testing:  (10767, 128, 51, 1)\n"
     ]
    }
   ],
   "source": [
    "rand = np.random.permutation(X.shape[0])\n",
    "n = 130000\n",
    "tr = rand[0:n]\n",
    "te = rand[n:]\n",
    "X_tr = X[tr]\n",
    "Y_tr = Y[tr]\n",
    "\n",
    "X_te = X[te]\n",
    "Y_te = Y[te]\n",
    "\n",
    "print('Shape of training: ',X_tr.shape)\n",
    "print('Shape of testing: ',X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " In training set\n",
      "Number of samples in class: 0 =  8717\n",
      "Number of samples in class: 1 =  8768\n",
      "Number of samples in class: 2 =  8695\n",
      "Number of samples in class: 3 =  8765\n",
      "Number of samples in class: 4 =  8703\n",
      "Number of samples in class: 5 =  8753\n",
      "Number of samples in class: 6 =  8747\n",
      "Number of samples in class: 7 =  8776\n",
      "Number of samples in class: 8 =  8750\n",
      "Number of samples in class: 9 =  8832\n",
      "Number of samples in class: 10 =  37906\n",
      "Number of samples in class: 11 =  4588\n",
      "\n",
      " In testing set\n",
      "Number of samples in class: 0 =  719\n",
      "Number of samples in class: 1 =  720\n",
      "Number of samples in class: 2 =  717\n",
      "Number of samples in class: 3 =  735\n",
      "Number of samples in class: 4 =  725\n",
      "Number of samples in class: 5 =  715\n",
      "Number of samples in class: 6 =  721\n",
      "Number of samples in class: 7 =  744\n",
      "Number of samples in class: 8 =  750\n",
      "Number of samples in class: 9 =  676\n",
      "Number of samples in class: 10 =  3133\n",
      "Number of samples in class: 11 =  412\n"
     ]
    }
   ],
   "source": [
    "#In training set \n",
    "print('\\n In training set')\n",
    "for lab in range(0,12):\n",
    "    print('Number of samples in class: '+str(lab) +' = ',len(np.where(Y_tr==lab)[0]))\n",
    "\n",
    "#In testing set \n",
    "print('\\n In testing set')\n",
    "for lab in range(0,12):\n",
    "    print('Number of samples in class: '+str(lab) +' = ',len(np.where(Y_te==lab)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding output labels Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130000, 12)\n",
      "(10767, 12)\n"
     ]
    }
   ],
   "source": [
    "Y_tr = to_categorical(Y_tr)\n",
    "Y_te = to_categorical(Y_te)\n",
    "print(Y_tr.shape)\n",
    "print(Y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 51, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 6, 256)        295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              6292480   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                6156      \n",
      "=================================================================\n",
      "Total params: 7,211,276\n",
      "Trainable params: 7,211,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (128,51,1)\n",
    "\n",
    "model = Sequential([\n",
    "    BatchNormalization(axis = -1,input_shape = input_shape),\n",
    "\n",
    "    Conv2D(32, (2, 2),strides = (1,1),padding='same',activation='relu'),\n",
    "    BatchNormalization(axis = -1),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None) ,   \n",
    "    \n",
    "   \n",
    "    Conv2D(64, (2, 2),strides = (1,1),padding='same',activation='relu'),\n",
    "    BatchNormalization(axis = -1),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)  ,\n",
    "    \n",
    "    \n",
    "    Conv2D(128, (2, 2),strides = (1,1), padding='same',activation='relu'),\n",
    "    BatchNormalization(axis = -1),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None) ,\n",
    "\n",
    "    \n",
    "    Conv2D(256, (2, 2),strides = (1,1),padding='same',activation='relu'),\n",
    "    BatchNormalization(axis = -1),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None) ,\n",
    "    \n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    \n",
    "    Dense(512,activation = 'relu'),    \n",
    "    Dense(12,activation='softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.loss = []\n",
    "        self.val_acc =[]\n",
    "        self.acc = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history_cb = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 130000 samples, validate on 10767 samples\n",
      "Epoch 1/1\n",
      "130000/130000 [==============================] - 2797s 22ms/step - loss: 0.7620 - acc: 0.7414 - val_loss: 0.5061 - val_acc: 0.8247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbb1fecfeb8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = optimizers.Adam(lr=0.001) \n",
    "model.compile(optimizer=opt,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "batch_size = 100\n",
    "model.fit(np.array(X_tr), np.array(Y_tr), batch_size=batch_size, epochs=1, verbose=1, validation_data=(np.array(X_te), np.array(Y_te)), callbacks = [history_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "with open('models/model2_json.pkl', 'wb') as m:\n",
    "    pickle.dump(json_string, m)\n",
    "model.save_weights('models/model2_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model reconstruction from JSON:\n",
    "json_string = pickle.load( open( \"models/model2_json.pkl\", \"rb\" ) )\n",
    "model = model_from_json(json_string)\n",
    "model.load_weights('models/model2_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb666573c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting loss\n",
    "plt.plot(history_cb.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "\n",
      "[[ 0.75  0.05  0.02  0.02  0.01  0.06  0.01  0.03  0.01  0.01  0.    0.  ]\n",
      " [ 0.03  0.78  0.01  0.04  0.01  0.03  0.02  0.02  0.02  0.    0.01  0.01]\n",
      " [ 0.01  0.02  0.79  0.01  0.01  0.04  0.04  0.02  0.02  0.03  0.01  0.01]\n",
      " [ 0.03  0.11  0.03  0.72  0.    0.04  0.03  0.01  0.01  0.    0.    0.  ]\n",
      " [ 0.    0.01  0.02  0.01  0.74  0.1   0.02  0.02  0.06  0.    0.    0.  ]\n",
      " [ 0.    0.01  0.02  0.01  0.04  0.87  0.01  0.    0.01  0.    0.    0.  ]\n",
      " [ 0.    0.03  0.05  0.02  0.01  0.04  0.76  0.01  0.02  0.    0.01  0.  ]\n",
      " [ 0.01  0.02  0.03  0.02  0.02  0.04  0.01  0.78  0.05  0.    0.01  0.  ]\n",
      " [ 0.01  0.01  0.03  0.01  0.07  0.05  0.03  0.03  0.75  0.    0.01  0.01]\n",
      " [ 0.01  0.02  0.06  0.03  0.    0.03  0.03  0.01  0.01  0.77  0.01  0.  ]\n",
      " [ 0.02  0.08  0.01  0.02  0.03  0.08  0.02  0.01  0.02  0.    0.93  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_te)\n",
    "#Converting from one hot back to integers\n",
    "y_pred = [np.where(r==np.max(r))[0][0] for r in p]\n",
    "\n",
    "\n",
    "a = Y_te\n",
    "#Converting from one hot back to integers\n",
    "y_true = [np.where(r==1)[0][0] for r in a ]\n",
    "\n",
    "C = sklearn.metrics.confusion_matrix(y_true,y_pred, labels=None, sample_weight=None)\n",
    "S = np.sum(np.array(C),axis=1)\n",
    "C_N = C/S\n",
    "print('Normalized confusion matrix\\n')\n",
    "print(np.array_str(C_N, precision=2, suppress_small=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
